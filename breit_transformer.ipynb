{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c472b8915bc419c743ebcff76dbcf6e203ef99bf90689a3fba2566158d7e07a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 268M/268M [00:07<00:00, 34.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "hf = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breit29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\" British prime minister Boris Johnson has gone on all in on Democratic presidential hopeful Joe Biden, congratulating him on an election “win” still contested by the sitting President after much of the mainstream media declared him the victor. While votes for the presidency are still being counted — a task the Democrats were previously adamant must be completed before any declaration of victory — and no results have been certified, mainstream media outlets from CNN to Fox News have already crowned Mr Biden the winner.   President Trump and his team insist the race\\xa0“is far from over”, alleging improprieties in the way ballots were cast and counted. “We all know why Joe Biden is rushing to falsely pose as the winner, and why his media allies are trying so hard to help him: they don’t want the truth to be exposed”, he said. Nevertheless, despite the lack of a Trump concession or certification of the results, some international leaders, perhaps seeking to curry favour with a new administration, are already rushing to congratulate the 77-year-old Democrat and his running mate — including Britain’s Boris Johnson.   Congratulations @JoeBiden and @KamalaHarris pic.twitter.com/xrpE99W4c4 — Boris Johnson (@BorisJohnson) November 7, 2020 “Congratulations to Joe Biden on his election as President of the United States and to Kamala Harris on her historic achievement,” wrote the Conservative Party politician in a message shared on social media. “The U.S. is our most important ally and I look forward to working closely together on our shared priorities, from climate change to trade and security.” Johnson’s snub to the sitting President may come as something of a surprise to observers aware of Biden’s more or less open hostility to Brexit, which stands in sharp contrast to Trump’s early, consistent, and enthusiastic support for Britain’s (still unimplemented) decision to reclaim full sovereignty from the European Union, as well as the media’s habit of referring to him as the “British Trump”. In reality, the economically neoliberal, pro-immigration Briton has never been very similar to his American counterpart, and slammed him when he was merely a candidate for the Republican nomination, which he was not expected to win. “When Donald Trump says that there are parts of London that are no-go areas, I think he’s betraying a quite stupefying ignorance that makes him, frankly, unfit to hold the office of President of the United States,” he said in an interview in 2015, when he was Mayor of London. “I would invite him to come and see the whole of London and take him round the city except that I wouldn’t want to expose Londoners to any unnecessary risk of meeting Donald Trump,” he added.  Farage Says Post-Brexit Britain Needs Trump, But Boris Govt 'Woos' Biden https://t.co/WQzEdNBttG — Breitbart London (@BreitbartLondon) October 11, 2020 Follow Jack Montgomery on Twitter:\\xa0@JackBMontgomery Follow Breitbart London on Facebook:\\xa0Breitbart London \""
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "art = df.article[150]\n",
    "art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9944175481796265}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "hf(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.7.0-cp38-none-macosx_10_9_x86_64.whl (108.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 108.1 MB 11.2 MB/s \n",
      "\u001b[?25hCollecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/metis/lib/python3.8/site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: future in /opt/anaconda3/envs/metis/lib/python3.8/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/metis/lib/python3.8/site-packages (from torch) (1.19.1)\n",
      "Installing collected packages: dataclasses, torch\n",
      "Successfully installed dataclasses-0.6 torch-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1.34G/1.34G [00:38<00:00, 34.7MB/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-785e3dcee700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0manswer_start_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_end_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0manswer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_start_scores\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the most likely beginning of answer with the argmax of the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0manswer_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_end_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Get the most likely end of answer with the argmax of the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0manswer_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", return_dict=True)\n",
    "\n",
    "questions = [\"Who is Donald Trump?\", \"What do the Democrats want?\"]\n",
    "for question in questions:\n",
    "    inputs = tokenizer(question, art, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(**inputs)\n",
    "    answer_start = torch.argmax(answer_start_scores)  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1.62k/1.62k [00:00<00:00, 540kB/s]\n",
      "Downloading: 100%|██████████| 1.22G/1.22G [00:36<00:00, 33.9MB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 4.74MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 4.68MB/s]\n",
      "Downloading: 100%|██████████| 26.0/26.0 [00:00<00:00, 10.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10760631 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(string_art, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_art = ' '.join(df.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.article[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}